{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 \n",
    "`- 652115013 Narongchai Rongthong`\n",
    "\n",
    "- Use the method discussed in this chapter to find and rank 5 misspelt candidates for a typo word clowd.\n",
    "    - Explain and choose 5 candidates from https://www.dcode.fr/levenshtein-distanceLinks to an external site. that are each one edit distance away from the word clowd. (1 pt)\n",
    "- Create p(x|w) table. (1 pt)\n",
    "- Create p(x|w)p(w) table using COCA, WIKI, and IULA (one each) (0.5 pt each = 1.5 pt in total)\n",
    "- Bring context into account, but this time uses COCA, WIKI, and IULA (one each) (0.5 pt each = 1.5 pt in total)\n",
    "    - Make one sentence by yourself to show that corpus become less dominant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Q1 `- Use the method discussed in this chapter to find and rank 5 misspelt candidates for a typo word clowd.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Candidate generation (COCA)\n",
    "- Firstly we're utilizing the Corpus of Contemporary English (COCA — https://www.english-corpora.org/coca/) as the reference corpus.\n",
    "    - As of of 2019, T ~ 1,001,610,938 terms\n",
    "    - Candidates was taken from https://www.dcode.fr/levenshtein-distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we got the frequecies of:\n",
    "- CLOD = 282\n",
    "- CLOW = 63\n",
    "- CLOUD = 28077\n",
    "- CLOWN = 7190\n",
    "- CROWD = 56835"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Now we can start writing code to rank their probability`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "      <th>P(w)</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLOD</td>\n",
       "      <td>282</td>\n",
       "      <td>2.815464e-07</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLOW</td>\n",
       "      <td>63</td>\n",
       "      <td>6.289867e-08</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLOUD</td>\n",
       "      <td>28077</td>\n",
       "      <td>2.803184e-05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CLOWN</td>\n",
       "      <td>7190</td>\n",
       "      <td>7.178436e-06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CROWD</td>\n",
       "      <td>56835</td>\n",
       "      <td>5.674359e-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  frequency          P(w)  rank\n",
       "0   CLOD        282  2.815464e-07     4\n",
       "1   CLOW         63  6.289867e-08     5\n",
       "2  CLOUD      28077  2.803184e-05     2\n",
       "3  CLOWN       7190  7.178436e-06     3\n",
       "4  CROWD      56835  5.674359e-05     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Create a DataFrame with words and their frequencies\n",
    "words = ['CLOD', 'CLOW', 'CLOUD', 'CLOWN', 'CROWD']\n",
    "frequencies = [282, 63, 28077, 7190, 56835]\n",
    "COCA = pd.DataFrame(list(zip(words, frequencies)), columns=['word', 'frequency'])\n",
    "\n",
    "# COCA population (As of of 2019, T ~ 1,001,610,938 terms)\n",
    "COCA_pop = 1001610938 \n",
    "\n",
    "# Calculate the probability\n",
    "COCA['P(w)'] = COCA['frequency'] / COCA_pop\n",
    "\n",
    "# Rank the words by their frequency (highest rank for most frequent)\n",
    "COCA['rank'] = COCA['frequency'].rank(ascending=False, method='min').astype(int)\n",
    "\n",
    "COCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ranking by frequency reflects the likelihood of each word appearing in the corpus, and thus indicates its likelihood of being the correct word.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "Q1.1 `- Explain and choose 5 candidates from https://www.dcode.fr/levenshtein-distanceLinks to an external site. that are each one edit distance away from the word clowd. (1 pt)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query result from the site\n",
    "\n",
    "<div>\n",
    "    <img src=\"src/image.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> This shows these 5 candidates that are one edits away from the word `CLOWD` </b>\n",
    "\n",
    "    - CLOD\t1\n",
    "    - CLOW\t1\n",
    "    - CLOUD\t1\n",
    "    - CLOWN\t1\n",
    "    - CROWD\t1\n",
    "\n",
    "These words are considered one edit away from CLOWD because they can be transformed into CLOWD through a single edit operation. \n",
    "\n",
    "- The typical edit operations are:\n",
    "    - Insertion: Adding a single character.\n",
    "    - Deletion: Removing a single character.\n",
    "    - Substitution: Replacing a single character with another.\n",
    "    - Transposition (optional in some spell-correction algorithms): Swapping two adjacent characters.\n",
    "\n",
    "<b>So the operations for each words would be</b>\n",
    "\n",
    "`CLOWD -> CLOD:`\n",
    "\n",
    "- Deletion: Remove the letter W.\n",
    "\n",
    "`CLOWD -> CLOW:`\n",
    "\n",
    "- Deletion: Remove the letter D.\n",
    "\n",
    "`CLOWD -> CLOUD:`\n",
    "\n",
    "- Substitution: Replace the letter W in CLOWD with U.\n",
    "\n",
    "`CLOWD -> CLOWN:`\n",
    "\n",
    "- Substitution: Replace the letter D in CLOWD with N.\n",
    "\n",
    "`CLOWD -> CROWD:`\n",
    "\n",
    "- Substitution: Replace the letter L in CLOWD with R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Q2 `- Create p(x|w) table. (1 pt)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this we consult the collected list of errors, e.g., Peter Norvig’s collections http://norvig.com/ngrams `/count_1edit.txt`<br>\n",
    "- so we can find more probable correct spelling based on the common letter misspelled\n",
    "\n",
    "*Note we cannot model unseen errors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      edit\n",
      "term      \n",
      "e|i    917\n",
      "a|e    856\n",
      "i|e    771\n",
      "e|a    749\n",
      "a|i    559\n"
     ]
    }
   ],
   "source": [
    "norvig = pd.read_csv('http://norvig.com/ngrams/count_1edit.txt', sep='\\t',encoding = \"ISO-8859-1\", header=None)\n",
    "norvig.columns = ['term', 'edit']\n",
    "norvig = norvig.set_index('term')\n",
    "print(norvig.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we get (count_big.txt) from Peter Norvig’s collection at http://norvig.com/ngrams `/count_big.txt`<br>\n",
    "This allows us to determine the prior probability of a word's occurrence in general usage.\n",
    "\n",
    "- This file contains unigram term frequencies (single-word occurrences) from a large corpus of text.\n",
    "- The data provides the frequency (freq) of each term (term) in the corpus.\n",
    "\n",
    "*Rare words may have less reliable estimates.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    term   freq\n",
      "0      a  21160\n",
      "1    aah      1\n",
      "2  aaron      5\n",
      "3     ab      2\n",
      "4  aback      3\n"
     ]
    }
   ],
   "source": [
    "norvig_orig = pd.read_csv('http://norvig.com/ngrams/count_big.txt',sep='\\t', encoding = \"ISO-8859-1\", header=None)\n",
    "norvig_orig = norvig_orig.dropna()\n",
    "norvig_orig.columns=['term','freq']\n",
    "print(norvig_orig.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Q3 `- Create p(x|w)p(w) table using COCA, WIKI, and IULA (one each) (0.5 pt each = 1.5 pt in total)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Q4 : \n",
    "- `Bring context into account, but this time uses COCA, WIKI, and IULA (one each) (0.5 pt each = 1.5 pt in total)`\n",
    "    - `Make one sentence by yourself to show that corpus become less dominant.`    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SE-IR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
