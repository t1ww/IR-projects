{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_data():\n",
    "    data = pd.read_csv('../Week 1/resource/software_developer_united_states_1971_20191023_1.csv')\n",
    "    description = data['job_description']\n",
    "    cleaned_description = description.apply(lambda s: s.translate(str.maketrans('', '', string.punctuation + u'\\xa0')))\n",
    "    cleaned_description = cleaned_description.apply(lambda s: s.lower())\n",
    "    cleaned_description = cleaned_description.apply(lambda s: s.translate(str.maketrans(string.whitespace, ' '*len(string.whitespace), '')))\n",
    "    cleaned_description = cleaned_description.drop_duplicates()\n",
    "    return cleaned_description\n",
    "\n",
    "def simple_tokenize(data):\n",
    "    cleaned_description = data.apply(lambda s: [x.strip() for x in s.split()])\n",
    "    return cleaned_description\n",
    "\n",
    "def parse_job_description():\n",
    "    cleaned_description = get_and_clean_data()\n",
    "    cleaned_description = simple_tokenize(cleaned_description)\n",
    "    return cleaned_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Page 58, 59** : Distributed indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fault tolerant matter\n",
    "\n",
    "    - If in a non-fault-tolerant system with 1000 nodes, each node has 99.9% uptime,\n",
    "    what is the uptime of the entire system?\n",
    "        - 0.9991000 â‰ˆ 0.368 which is around 36.8%\n",
    "\n",
    "- This result means the system has an uptime of approximately 36.8%, indicating\n",
    "that 63.2% of the time, one or more nodes will be down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "Sampling: [node_states]\n"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "import numpy as np\n",
    "\n",
    "num_nodes = 500\n",
    "node_uptime = 0.99\n",
    "num_simulations = 5000\n",
    "\n",
    "with pm.Model() as model:\n",
    "    node_states = pm.Bernoulli('node_states', p=node_uptime, size=(num_simulations, num_nodes))\n",
    "    system_uptime = pm.math.prod(node_states, axis=1)\n",
    "    mean_system_uptime = pm.Deterministic('mean_system_uptime', pm.math.mean(system_uptime))\n",
    "    prior_checks = pm.sample_prior_predictive()\n",
    "\n",
    "node_states_samples = prior_checks.prior['node_states'].values\n",
    "node_states_samples = np.squeeze(node_states_samples)\n",
    "nodes_up_count = np.sum(node_states_samples, axis=1)\n",
    "\n",
    "system_uptime_samples = prior_checks.prior['mean_system_uptime'].values\n",
    "overall_mean_system_uptime = np.mean(system_uptime_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Mean System Uptime: 0.006555600000000001\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall Mean System Uptime:\", overall_mean_system_uptime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Page 67, 69** : Compression for sparse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 1 0 0]\n",
      " [0 0 2 0 0 1]\n",
      " [0 0 0 2 0 0]]\n",
      "  (0, 0)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 2)\t2\n",
      "  (1, 5)\t1\n",
      "  (2, 3)\t2\n",
      "  (0, 0)\t1\n",
      "  (2, 0)\t2\n",
      "[[1 0 0 1 0 0]\n",
      " [0 0 2 0 0 1]\n",
      " [0 0 0 2 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# dense to sparse\n",
    "from numpy import array\n",
    "from scipy.sparse import coo_matrix, csr_matrix, csc_matrix, dok_matrix, lil_matrix\n",
    "# create dense matrix\n",
    "A = array([[1, 0, 0, 1, 0, 0], [0, 0, 2, 0, 0, 1], [0, 0, 0, 2, 0, 0]])\n",
    "print(A)\n",
    "\n",
    "# convert to sparse matrix (COO method)\n",
    "S = coo_matrix(A)\n",
    "print(S)\n",
    "\n",
    "print(S.tocsr()[:,3])\n",
    "\n",
    "# reconstruct dense matrix\n",
    "B = S.todense()\n",
    "print(B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00013275628899922593"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "times = 100000\n",
    "timeit.timeit(lambda : dok_matrix(B), number=times)/times\n",
    "timeit.timeit(lambda : lil_matrix(B), number=times)/times\n",
    "timeit.timeit(lambda : csr_matrix(B), number=times)/times\n",
    "timeit.timeit(lambda : csc_matrix(B), number=times)/times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [chosen, softwar, develop, part, larger, engin...\n",
       "1       [posit, lead, softwar, develop, locat, middlet...\n",
       "2       [senior, softwar, develop, hoboken, start, mon...\n",
       "3       [client, multin, publish, educ, compani, seek,...\n",
       "4       [posit, lead, softwar, develop, locat, philade...\n",
       "                              ...                        \n",
       "1230    [job, summari, softwar, develop, rubi, rail, c...\n",
       "1231    [globalstar, seek, softwar, develop, join, tea...\n",
       "1232    [softwar, engin, servic, rockstar, level, expe...\n",
       "1233    [job, titl, lead, softwar, developertechn, net...\n",
       "1234    [ref, classif, softwar, engin, compens, year, ...\n",
       "Name: job_description, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ordered_set import OrderedSet\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "#limit to just 1000 rows\n",
    "cleaned_description = get_and_clean_data()[:1000]\n",
    "\n",
    "#replace non alphabets with spaces, and collapse spaces\n",
    "cleaned_description = cleaned_description.apply(lambda s: re.sub(r'[^A-Za-z]', ' ', s))\n",
    "cleaned_description = cleaned_description.apply(lambda s: re.sub(r'\\s+', ' ', s))\n",
    "\n",
    "#tokenize\n",
    "tokenized_description = cleaned_description.apply(lambda s: word_tokenize(s))\n",
    "\n",
    "#remove stop words\n",
    "stop_dict = set(stopwords.words())\n",
    "sw_removed_description = tokenized_description.apply(lambda s: list(OrderedSet(s) - stop_dict))\n",
    "sw_removed_description = sw_removed_description.apply(lambda s: [word for word in s if len(word)>2])\n",
    "\n",
    "#create stem caches\n",
    "concated = np.unique(np.concatenate([s for s in tokenized_description.values]))\n",
    "stem_cache = {}\n",
    "ps = PorterStemmer()\n",
    "for s in concated:\n",
    "    stem_cache[s] = ps.stem(s)\n",
    "\n",
    "#stem\n",
    "stemmed_description = sw_removed_description.apply(lambda s: [stem_cache[w] for w in s])\n",
    "stemmed_description"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SE-IR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
